{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "TiBT-CLTH-0N",
        "outputId": "8609ef7b-da38-4214-941d-9320dbcc8424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from aif360) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'days_b_screening_arrest'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'days_b_screening_arrest'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-855955168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Load and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_compas_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Create AIF360 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-855955168.py\u001b[0m in \u001b[0;36mload_compas_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Filter as per ProPublica's analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     df = df[(df['days_b_screening_arrest'] <= 30) & \n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_b_screening_arrest'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_recid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'days_b_screening_arrest'"
          ]
        }
      ],
      "source": [
        "# COMPLETE AI FAIRNESS AUDIT IMPLEMENTATION\n",
        "\n",
        "# 1. SETUP AND IMPORTS\n",
        "!pip install aif360 pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# 2. DATA PREPARATION\n",
        "def load_compas_data():\n",
        "    \"\"\"Load and preprocess COMPAS dataset\"\"\"\n",
        "    df = pd.read_csv('compas-scores-two-years.csv')\n",
        "\n",
        "    # Filter as per ProPublica's analysis\n",
        "    df = df[(df['days_b_screening_arrest'] <= 30) &\n",
        "            (df['days_b_screening_arrest'] >= -30) &\n",
        "            (df['is_recid'] != -1) &\n",
        "            (df['c_charge_degree'] != 'O') &\n",
        "            (df['score_text'] != 'N/A')]\n",
        "\n",
        "    # Prepare features and target\n",
        "    features = df.drop(['two_year_recid', 'race', 'sex', 'age', 'c_charge_desc'], axis=1)\n",
        "    X = pd.get_dummies(features)\n",
        "    y = np.array(df['two_year_recid'])  # Recidivism outcome\n",
        "    protected = np.array(df['race'] == 'African-American', dtype=int)  # 1 if African-American\n",
        "\n",
        "    return X, y, protected\n",
        "\n",
        "# 3. FAIRNESS ANALYSIS\n",
        "def analyze_fairness(dataset):\n",
        "    \"\"\"Calculate and display fairness metrics\"\"\"\n",
        "    metric = BinaryLabelDatasetMetric(\n",
        "        dataset,\n",
        "        unprivileged_groups=[{'race': 1}],\n",
        "        privileged_groups=[{'race': 0}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"FAIRNESS METRICS ANALYSIS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Disparate Impact: {metric.disparate_impact():.3f} (ideal: 1.0)\")\n",
        "    print(f\"Statistical Parity Difference: {metric.statistical_parity_difference():.3f} (ideal: 0)\")\n",
        "    print(f\"Mean Difference: {metric.mean_difference():.3f} (ideal: 0)\")\n",
        "\n",
        "    return metric\n",
        "\n",
        "# 4. BIAS MITIGATION\n",
        "def mitigate_bias(train_data):\n",
        "    \"\"\"Apply reweighing to mitigate bias\"\"\"\n",
        "    RW = Reweighing(\n",
        "        unprivileged_groups=[{'race': 1}],\n",
        "        privileged_groups=[{'race': 0}]\n",
        "    )\n",
        "    return RW.fit_transform(train_data)\n",
        "\n",
        "# 5. MODEL TRAINING AND EVALUATION\n",
        "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Train logistic regression model and evaluate performance\"\"\"\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MODEL PERFORMANCE\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    return model, y_pred\n",
        "\n",
        "# 6. VISUALIZATION\n",
        "def plot_fairness_comparison(original_metrics, mitigated_metrics):\n",
        "    \"\"\"Visualize fairness metrics before/after mitigation\"\"\"\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Original': original_metrics,\n",
        "        'Mitigated': mitigated_metrics\n",
        "    }, index=['Disparate Impact', 'Statistical Parity Difference'])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    metrics_df.plot.bar(ax=ax)\n",
        "    ax.axhline(y=0, color='k', linestyle='--')\n",
        "    ax.axhline(y=1, color='g', linestyle='--', alpha=0.3)\n",
        "    ax.set_title('Fairness Metrics Comparison', pad=20)\n",
        "    ax.set_ylabel('Metric Value')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fairness_comparison.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and prepare data\n",
        "    X, y, protected = load_compas_data()\n",
        "\n",
        "    # Create AIF360 dataset\n",
        "    dataset = BinaryLabelDataset(\n",
        "        df=pd.concat([X, pd.Series(y, name='two_year_recid')], axis=1),\n",
        "        label_names=['two_year_recid'],\n",
        "        protected_attribute_names=['race'],\n",
        "        privileged_protected_attributes=[0]\n",
        "    )\n",
        "\n",
        "    # Split data\n",
        "    train, test = dataset.split([0.7], shuffle=True, seed=42)\n",
        "\n",
        "    # Analyze original fairness\n",
        "    print(\"\\nOriginal Data Fairness:\")\n",
        "    orig_metrics = analyze_fairness(train)\n",
        "\n",
        "    # Mitigate bias\n",
        "    train_transformed = mitigate_bias(train)\n",
        "    print(\"\\nAfter Bias Mitigation:\")\n",
        "    trans_metrics = analyze_fairness(train_transformed)\n",
        "\n",
        "    # Train models\n",
        "    ## Original data\n",
        "    X_train_orig = train.features\n",
        "    y_train_orig = train.labels.ravel()\n",
        "    X_test = test.features\n",
        "    y_test = test.labels.ravel()\n",
        "\n",
        "    ## Transformed data\n",
        "    train_trans_df = train_transformed.convert_to_dataframe()[0]\n",
        "    X_train_trans = train_trans_df.drop('two_year_recid', axis=1)\n",
        "    y_train_trans = train_trans_df['two_year_recid']\n",
        "\n",
        "    # Train and evaluate models\n",
        "    print(\"\\nOriginal Data Model:\")\n",
        "    orig_model, orig_pred = train_and_evaluate(X_train_orig, y_train_orig, X_test, y_test)\n",
        "\n",
        "    print(\"\\nMitigated Data Model:\")\n",
        "    trans_model, trans_pred = trans_model, trans_pred = train_and_evaluate(X_train_trans, y_train_trans, X_test, y_test)\n",
        "\n",
        "    # Compare fairness metrics\n",
        "    plot_fairness_comparison(\n",
        "        [orig_metrics.disparate_impact(), orig_metrics.statistical_parity_difference()],\n",
        "        [trans_metrics.disparate_impact(), trans_metrics.statistical_parity_difference()]\n",
        "    )\n",
        "\n",
        "    # Generate classification fairness metrics\n",
        "    test_pred = test.copy()\n",
        "    test_pred.labels = trans_pred.reshape(-1, 1)\n",
        "\n",
        "    class_metric = ClassificationMetric(\n",
        "        test,\n",
        "        test_pred,\n",
        "        unprivileged_groups=[{'race': 1}],\n",
        "        privileged_groups=[{'race': 0}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CLASSIFICATION FAIRNESS METRICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"False Positive Rate Difference: {class_metric.false_positive_rate_difference():.3f} (ideal: 0)\")\n",
        "    print(f\"False Negative Rate Difference: {class_metric.false_negative_rate_difference():.3f} (ideal: 0)\")\n",
        "    print(f\"Equal Opportunity Difference: {class_metric.equal_opportunity_difference():.3f} (ideal: 0)\")\n",
        "    print(f\"Average Odds Difference: {class_metric.average_odds_difference():.3f} (ideal: 0)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can download it programmatically using:\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = \"https://www.propublica.org/datastore/dataset/6b259406-68c5-49e5-a83e-6a4dbd5ef04b/resource/52fd8e92-571c-4c29-9a4e-80def71b3682/download/compas-scores-two-years.csv\"\n",
        "urllib.request.urlretrieve(url, \"compas-scores-two-years.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3ioHIfoKHzr",
        "outputId": "cbb43e0e-ad02-4934-edc4-5e02069851ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('compas-scores-two-years.csv', <http.client.HTTPMessage at 0x7f15f7a65350>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}